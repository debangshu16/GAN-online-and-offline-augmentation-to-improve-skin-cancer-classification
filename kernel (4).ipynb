{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-56d0676fe176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrandom_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "np.random.seed(10)\n",
    "random_dim=100\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../input/HAM10000_metadata.csv\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "532c014feaba600504fe1432c569d05e7bc3727c"
   },
   "outputs": [],
   "source": [
    "meta.dx.value_counts().plot.bar(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83db94e93b3a34abce6349c4a03e23561e284e32"
   },
   "outputs": [],
   "source": [
    "classes = list(meta.dx.value_counts().keys())[0:4]\n",
    "meta = meta[meta.dx.isin(classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed0f1e663ed7d07b8636edd97629da0e4b2524de"
   },
   "outputs": [],
   "source": [
    "clss={}\n",
    "for num,name in enumerate(classes):\n",
    "    clss[name]=num\n",
    "    \n",
    "def label_encode(label):\n",
    "    return clss[label]\n",
    "\n",
    "meta[\"class\"] = meta.dx.apply(label_encode)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "225cf07ab0be972c3e84b15656bf9935df97b4d5"
   },
   "outputs": [],
   "source": [
    "from os.path import isfile\n",
    "def extend_path(p):\n",
    "    if isfile(\"../input/ham10000_images_part_1/\"+p+\".jpg\"):\n",
    "        return \"../input/ham10000_images_part_1/\"+p+\".jpg\"\n",
    "    if isfile(\"../input/ham10000_images_part_2/\"+p+\".jpg\"):\n",
    "        return \"../input/ham10000_images_part_2/\"+p+\".jpg\"\n",
    "meta[\"image_path\"] = meta[\"image_id\"]\n",
    "meta[\"image_path\"] = meta[\"image_path\"].apply(extend_path)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8ccbb8b44cc272fef2b97968e124d0e6da34656"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#with h5py.File(\"../working/images.hdf5\", \"w\") as f:\n",
    "#imgs = {}\n",
    "labels=[]\n",
    "Y=[]\n",
    "trainX=[]\n",
    "for c in classes:\n",
    "    temp = meta[meta[\"dx\"]==c]\n",
    "    for path in temp[\"image_path\"]:\n",
    "        image=Image.open(path)\n",
    "        image=image.resize([100,75])\n",
    "        trainX.append(np.asarray(image))\n",
    "        labels.append(np.eye(len(classes))[clss[c]])\n",
    "        Y.append(clss[c])\n",
    "    #img_arr = np.array(img_arr)\n",
    "    #imgs[c] = img_arr\n",
    "    #dset = f.create_dataset(c,data=img_arr)\n",
    "    #del img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "264f42afc7d31d4bdf157768ee84e67f86d5dc46"
   },
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "labels = np.array(labels)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9a35bab2bfe1e9264ce3f52b5cf212cc99f2965"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "trainX,labels,Y=shuffle(trainX,labels,Y,random_state=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2be5bca1134821651a377876fc31175a52f5ca5b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX,testX,trainLabels,testLabels,trainY,testY=train_test_split(\n",
    "    trainX,labels,Y,test_size=0.15,random_state=42,stratify=Y)\n",
    "trainX,valX,trainLabels,valLabels,trainY,valY=train_test_split(\n",
    "    trainX,trainLabels,trainY,test_size=0.15,random_state=42,stratify=trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81e8258f934acc6024214fcbf66392010616d0f7"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D,BatchNormalization,Dense,Dropout,Flatten,MaxPooling2D,Reshape,Conv2DTranspose,Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu,sigmoid\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "def make_model(shape):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(16,(5,5),input_shape=shape,activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(160,activation=sigmoid))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(80,activation=sigmoid))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(len(classes),activation=\"softmax\"))\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c9c3010edd86d3bd28a6011bbc45db189eb91c5"
   },
   "outputs": [],
   "source": [
    "shape=(trainX.shape[1],trainX.shape[2],trainX.shape[3])\n",
    "model=make_model(shape)\n",
    "filepath=\"../working/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(trainX,trainLabels,validation_data=(valX,valLabels),epochs=10,callbacks=callbacks_list,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee03739c91c6f6f5adf8890d6b277a834c1582c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_pred=np.argmax(model.predict(testX),axis=1)\n",
    "acc=accuracy_score(testY,test_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39b2a5d6da1d9ccb0be87f9e7044999dea6ef4ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = {}\n",
    "for c in classes:\n",
    "    temp = meta[meta[\"dx\"]==c]\n",
    "    img_arr=[]\n",
    "    Y=[]\n",
    "    for path in temp[\"image_path\"]:\n",
    "        image=Image.open(path)\n",
    "        image=image.resize([100,75])\n",
    "        #labels.append(np.eye(len(classes))[clss[c]])\n",
    "        Y.append(clss[c])\n",
    "        img_arr.append(np.array(image))\n",
    "    img_arr = np.array(img_arr)\n",
    "    imgs[c] = img_arr\n",
    "    #labels[c] = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9cba73fd59c37a74aaedd505c107a20e2367b7c1"
   },
   "outputs": [],
   "source": [
    "len(imgs[\"bcc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24b8c3d44beb155638a4797205dd3ea7a7dbd5ab"
   },
   "outputs": [],
   "source": [
    "imgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84057e063c54210ede915d7eaa4c40f6ffc9bfd8"
   },
   "outputs": [],
   "source": [
    "# You will use the Adam optimizer\n",
    "def get_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "def get_generator(optimizer):\n",
    "    generator = Sequential([\n",
    "    # Layer 1\n",
    "    Dense(3*4*1000, input_shape=(100,)),\n",
    "    Reshape(target_shape=(3,4, 1000)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    # Layer 2\n",
    "    Conv2DTranspose(256, kernel_size=3, strides=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    # Layer 3\n",
    "    Conv2DTranspose(128, kernel_size=3, strides=5, padding='same'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    # Layer 4\n",
    "    Conv2DTranspose(3, kernel_size=5, strides=1, padding='same'),\n",
    "    Activation('tanh')\n",
    "])\n",
    "    generator.summary()\n",
    "    return generator\n",
    "\n",
    "def get_discriminator(optimizer):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(16,(5,5),input_shape=(75,100,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128,(3,3),activation=relu,padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(160,activation=sigmoid))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(80,activation=sigmoid))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d348f6f12ddfafb8feabb9610f6d386efca93ecf"
   },
   "outputs": [],
   "source": [
    "adam = get_optimizer()\n",
    "generator = get_generator(adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34e16c3b56b8518ba9767c6e42cb30c678ba4a00"
   },
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
    "    # We initially set trainable to False since we only want to train either the\n",
    "    # generator or discriminator at a time\n",
    "    discriminator.trainable = False\n",
    "    # gan input (noise) will be 100-dimensional vectors\n",
    "    gan_input = Input(shape=(random_dim,))\n",
    "    # the output of the generator (an image)\n",
    "    x = generator(gan_input)\n",
    "    # get the output of the discriminator (probability if the image is real or not)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d45cc0f666ea8fb9749c1c76f0bf63b8e02a16f"
   },
   "outputs": [],
   "source": [
    "# Create a wall of generated MNIST images\n",
    "def plot_generated_images(epoch, generator, examples=10, dim=(1, 10), figsize=(75, 100)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 75, 100, 3)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76f9cea6a4b08bab875743c636f3583c67946fb7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(trainX,epochs=1, batch_size=20):\n",
    "    \n",
    "    # Split the training data into batches of size batch_size\n",
    "    batch_count = trainX.shape[0] // batch_size\n",
    "    # The dimension of our random noise vector.\n",
    "    random_dim = 100\n",
    "    # Build our GAN netowrk\n",
    "    adam = get_optimizer()\n",
    "    generator = get_generator(adam)\n",
    "    discriminator = get_discriminator(adam)\n",
    "    gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in tqdm(range(batch_count)):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            image_batch = trainX[np.random.randint(0, trainX.shape[0], size=batch_size)]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generated_images = generator.predict(noise)\n",
    "            #print(image_batch.shape,generated_images.shape)\n",
    "            X = np.concatenate([image_batch, generated_images])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            # One-sided label smoothing\n",
    "            y_dis[:batch_size] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "\n",
    "        if e == 1 or e % 20 == 0:\n",
    "            plot_generated_images(e, generator)\n",
    "    \n",
    "    return generator,discriminator\n",
    "\n",
    "gen_bcc,dis_bcc = train(imgs[\"bcc\"],400,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f05b72543276b0ec1914e2ddcbe618087d7e6539"
   },
   "outputs": [],
   "source": [
    "imgs[\"bcc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83f1717a98d341d1399b837cca469004e17761fc"
   },
   "outputs": [],
   "source": [
    "plot_generated_images(400,gen_bcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "660a457d1195f1a2e5afb78a98a600f345cc51c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
